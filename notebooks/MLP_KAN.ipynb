{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Untitled7.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class TraditionalMLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers):\n",
        "        super(TraditionalMLP, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.Sequential(\n",
        "            nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim if i == num_layers - 1 else hidden_dim)\n",
        "        ) for i in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "oU2-vH6vK6Pa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715820769931,
          "user_tz": -540,
          "elapsed": 9419,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "def test_mlp():\n",
        "    model = TraditionalMLP(2, 1, 4, 2)\n",
        "    model.apply(weights_init)\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    print(\"Parameters: \", params)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=.1)\n",
        "    objective_function = lambda u, v: torch.exp(v ** 2 + torch.sin(torch.pi * u)) + v\n",
        "    with tqdm(range(1000)) as pbar:\n",
        "        for i in pbar:\n",
        "            loss = None\n",
        "\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                x = torch.rand(1024, 2)\n",
        "                y = model(x)\n",
        "\n",
        "                assert y.shape == (1024, 1)\n",
        "                nonlocal loss\n",
        "                u = x[:, 0]\n",
        "                v = x[:, 1]\n",
        "                loss = nn.functional.mse_loss(y.squeeze(-1), objective_function(u, v))\n",
        "\n",
        "                loss.backward()\n",
        "                return loss\n",
        "\n",
        "            optimizer.step(closure)\n",
        "            pbar.set_postfix(mse_loss=loss.item())"
      ],
      "metadata": {
        "id": "M52j35DRLpHY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715836687429,
          "user_tz": -540,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mlp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXVVNBlaLslm",
        "outputId": "bac262bc-9f28-41d4-e8f6-ac279b440912",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715836692845,
          "user_tz": -540,
          "elapsed": 3898,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:  57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 268.16it/s, mse_loss=2.13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TraditionalMLP(28 * 28, 10, 32, 2)\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXlJmyJ75V-w",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715834845980,
          "user_tz": -540,
          "elapsed": 354,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "27849636-3e4e-444f-f273-cf16230dff27"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on MNIST\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load MNIST\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "valset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "trainloader = DataLoader(trainset, batch_size=512, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=512, shuffle=False)\n",
        "\n",
        "# Define model\n",
        "model = TraditionalMLP(28 * 28, 10, 32, 2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Define optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "\n",
        "# Define loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(5):\n",
        "    # Train\n",
        "    model.train()\n",
        "    with tqdm(trainloader) as pbar:\n",
        "        for i, (images, labels) in enumerate(pbar):\n",
        "            images = images.view(-1, 28 * 28).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
        "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            images = images.view(-1, 28 * 28).to(device)\n",
        "            output = model(images)\n",
        "            val_loss += criterion(output, labels.to(device)).item()\n",
        "            val_accuracy += (\n",
        "                (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
        "            )\n",
        "    val_loss /= len(valloader)\n",
        "    val_accuracy /= len(valloader)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9TEZYZVwPxp",
        "outputId": "82a56473-6499-4156-de12-d0b6ef8f2761",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715821632674,
          "user_tz": -540,
          "elapsed": 76327,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.88it/s, accuracy=0.875, loss=0.394, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.47861494272947314, Val Accuracy: 0.8656594663858413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.99it/s, accuracy=0.854, loss=0.5, lr=0.0008]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Val Loss: 0.3532404191792011, Val Accuracy: 0.8962201297283172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  9.05it/s, accuracy=0.917, loss=0.292, lr=0.00064]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Val Loss: 0.3266025297343731, Val Accuracy: 0.9040843278169632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  9.03it/s, accuracy=0.927, loss=0.26, lr=0.000512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Val Loss: 0.31495350524783133, Val Accuracy: 0.9072437971830368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  9.06it/s, accuracy=0.938, loss=0.244, lr=0.00041]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Val Loss: 0.3057694613933563, Val Accuracy: 0.9112132340669632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TemperatureSoftmax(nn.Module):\n",
        "    def __init__(self, temperature=1, dim=None):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.softmax(input / self.temperature, dim=self.dim)\n",
        "\n",
        "class SplineMLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, control_points):\n",
        "        super(SplineMLP, self).__init__()\n",
        "\n",
        "        self.control_points = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim * control_points)\n",
        "        )\n",
        "\n",
        "        self.n = control_points\n",
        "        self.output_dim = output_dim\n",
        "        self.basis_network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(hidden_dim, control_points),\n",
        "            TemperatureSoftmax(0.5, dim=1)  # normalize the output to make it a proper basis function\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # bs, control points\n",
        "        basis_values = self.basis_network(x)  # learnable basis function\n",
        "        outputs = self.control_points(x).reshape(-1, self.n, self.output_dim)\n",
        "        outputs = torch.einsum('bno,bn->bo', outputs, basis_values)\n",
        "        return outputs\n",
        "\n",
        "class KAN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, control_points):\n",
        "        super(KAN, self).__init__()\n",
        "        self.fc1 = SplineMLP( input_dim, output_dim, hidden_dim, control_points)\n",
        "    def forward(self, x):\n",
        "        outputs = self.fc1(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "i-xkod2BGhjB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715835012492,
          "user_tz": -540,
          "elapsed": 440,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "def test_kan():\n",
        "  model = KAN(2, 1, 3, 5)\n",
        "  model.apply(weights_init)\n",
        "  model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "  print(\"Parameters: \", params)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=.1)\n",
        "  objective_function = lambda u, v: torch.exp(v ** 2 + torch.sin(torch.pi * u)) + v\n",
        "  with tqdm(range(1000)) as pbar:\n",
        "      for i in pbar:\n",
        "          loss = None\n",
        "\n",
        "          def closure():\n",
        "              optimizer.zero_grad()\n",
        "              x = torch.rand(1024, 2)\n",
        "              y = model(x)\n",
        "\n",
        "              assert y.shape == (1024, 1)\n",
        "              nonlocal loss\n",
        "              u = x[:, 0]\n",
        "              v = x[:, 1]\n",
        "              loss = nn.functional.mse_loss(y.squeeze(-1), objective_function(u, v))\n",
        "\n",
        "              loss.backward()\n",
        "              return loss\n",
        "\n",
        "          optimizer.step(closure)\n",
        "          pbar.set_postfix(mse_loss=loss.item())"
      ],
      "metadata": {
        "id": "dl_0e3S1rQY1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715836712983,
          "user_tz": -540,
          "elapsed": 363,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_kan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfQYAC3wrXmc",
        "outputId": "c7d377fd-d8eb-415e-911b-442297f54209",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715836719090,
          "user_tz": -540,
          "elapsed": 4629,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:  58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 230.50it/s, mse_loss=0.0421]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KAN(28 * 28, 10, 16, 4)\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcVCTB_S6Bgm",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715833448661,
          "user_tz": -540,
          "elapsed": 351,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c25ff7c7-90b3-444a-cd57-8ab9fdd0acc8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on MNIST\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load MNIST\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "valset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "trainloader = DataLoader(trainset, batch_size=512, shuffle=True)\n",
        "valloader = DataLoader(valset, batch_size=512, shuffle=False)\n",
        "\n",
        "# Define model\n",
        "model = KAN(28 * 28, 10, 32, 4)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "# Define optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# Define learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "\n",
        "# Define loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(5):\n",
        "    # Train\n",
        "    model.train()\n",
        "    with tqdm(trainloader) as pbar:\n",
        "        for i, (images, labels) in enumerate(pbar):\n",
        "            images = images.view(-1, 28 * 28).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            accuracy = (output.argmax(dim=1) == labels.to(device)).float().mean()\n",
        "            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item(), lr=optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valloader:\n",
        "            images = images.view(-1, 28 * 28).to(device)\n",
        "            output = model(images)\n",
        "            val_loss += criterion(output, labels.to(device)).item()\n",
        "            val_accuracy += (\n",
        "                (output.argmax(dim=1) == labels.to(device)).float().mean().item()\n",
        "            )\n",
        "    val_loss /= len(valloader)\n",
        "    val_accuracy /= len(valloader)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVm1GBUiEvGV",
        "outputId": "37a57af8-fe62-479c-f820-a3a10b5ed412",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1715833532314,
          "user_tz": -540,
          "elapsed": 77373,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.87it/s, accuracy=0.896, loss=0.488, lr=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.38142223209142684, Val Accuracy: 0.8984202653169632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.88it/s, accuracy=0.906, loss=0.27, lr=0.0008]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Val Loss: 0.28616719916462896, Val Accuracy: 0.9168485760688782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.95it/s, accuracy=0.896, loss=0.342, lr=0.00064]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Val Loss: 0.2480481218546629, Val Accuracy: 0.9259306073188782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.98it/s, accuracy=0.917, loss=0.291, lr=0.000512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Val Loss: 0.2346076589077711, Val Accuracy: 0.9322035849094391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:13<00:00,  8.65it/s, accuracy=0.969, loss=0.131, lr=0.00041]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Val Loss: 0.2127841033041477, Val Accuracy: 0.9388614445924759\n"
          ]
        }
      ]
    }
  ]
}